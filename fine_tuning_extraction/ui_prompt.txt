Write a Python streamlit application for extracting question/answer pairs from scientific papers for use in fine-tuning large language models.

Inputs: 
- Path to PDF papers (defaults to ./docs)
- Path to Prompt templates (defaults to ./extraction_prompts)
- Path to Output JSON files (defaults to ./output)

When the user clicks the process button, the application should read the input files, extract question/answer pairs from the scientific papers using the provided prompt templates, and save the extracted data in JSON format.

There is a .env file that has the following keys:

GOOGLE_API_KEY=xxxxxxxxxxxx
GOOGLE_MODEL=gemini-2.5-flash
SOURCE_DIR=./docs
OUTPUT_DIR=./output
PROMPT_DIR=./extraction_prompts

Every PDF should generate a separate JSON file for each prompt.  Put the JSON files in a folder with the same name as the corresponding PDF (minus the extension) in the OUTPUT_DIR.

Make sure to update the screen with progress.

If prompt fails due to the output not being valid JSON (or the wrong format), retry up to 3 times.  Other failures, should be output to the console with the input file name and input prompt file name plus the error message in a single line.

Give me a pip install for any required libraries.